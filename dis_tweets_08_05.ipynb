{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53219d1e-ed59-4e09-b98a-903df1f568fd",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.7-py3-none-any.whl (1.5 MB)\n",
      "Collecting regex>=2021.8.3\n",
      "  Using cached regex-2022.4.24-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (763 kB)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Installing collected packages: regex, nltk\n",
      "Successfully installed nltk-3.7 regex-2022.4.24\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.8.0-cp39-cp39-manylinux2010_x86_64.whl (497.6 MB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (4.0.1)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Using cached flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.25.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.1 MB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.19.3)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Using cached libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from tensorflow) (59.8.0)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Using cached tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.46.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.9/site-packages (from tensorflow) (1.21.5)\n",
      "Collecting gast>=0.2.1\n",
      "  Using cached gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Using cached tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Using cached keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0-py3-none-any.whl\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.10.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.7.0)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.1.1)\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, cachetools, requests-oauthlib, google-auth, werkzeug, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, wrapt, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.46.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.7 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.25.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109 werkzeug-2.1.2 wrapt-1.14.1\n",
      "Collecting spacy\n",
      "  Using cached spacy-3.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.7-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21 kB)\n",
      "Collecting wasabi<1.1.0,>=0.9.1\n",
      "  Using cached wasabi-0.9.1-py3-none-any.whl (26 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Using cached spacy_loggers-1.0.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy) (59.8.0)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (21.3)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.9\n",
      "  Using cached spacy_legacy-3.0.9-py2.py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (4.62.3)\n",
      "Collecting thinc<8.1.0,>=8.0.14\n",
      "  Using cached thinc-8.0.15-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (661 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Using cached langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (1.21.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy) (3.0.3)\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.1-py3-none-any.whl (27 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (128 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy) (2.27.1)\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.7-py3-none-any.whl (17 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3\n",
      "  Using cached srsly-2.4.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (457 kB)\n",
      "Collecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-cp39-cp39-manylinux2014_x86_64.whl (11.3 MB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy) (3.0.7)\n",
      "Collecting smart-open<6.0.0,>=5.0.0\n",
      "  Using cached smart_open-5.2.1-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (4.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy) (2.0.1)\n",
      "Installing collected packages: murmurhash, cymem, catalogue, wasabi, typer, srsly, smart-open, pydantic, preshed, blis, thinc, spacy-loggers, spacy-legacy, pathy, langcodes, spacy\n",
      "Successfully installed blis-0.7.7 catalogue-2.0.7 cymem-2.0.6 langcodes-3.3.0 murmurhash-1.0.7 pathy-0.6.1 preshed-3.0.6 pydantic-1.8.2 smart-open-5.2.1 spacy-3.3.0 spacy-legacy-3.0.9 spacy-loggers-1.0.2 srsly-2.4.3 thinc-8.0.15 typer-0.4.1 wasabi-0.9.1\n",
      "2022-05-07 11:52:28.586479: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-07 11:52:28.586630: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Collecting en-core-web-sm==3.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.3.0/en_core_web_sm-3.3.0-py3-none-any.whl (12.8 MB)\n",
      "     |████████████████████████████████| 12.8 MB 1.2 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: spacy<3.4.0,>=3.3.0.dev0 in /opt/conda/lib/python3.9/site-packages (from en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.4.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.6.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.27.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (21.3)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.21.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.8.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.7.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.15)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.62.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.9)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (59.8.0)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (0.9.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.0.7)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.0.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (4.0.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2021.10.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.4.0,>=3.3.0.dev0->en-core-web-sm==3.3.0) (2.0.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.3.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install tensorflow\n",
    "!pip install -U spacy\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54eca46b-8392-40b8-9bad-97de98a00654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "import string\n",
    "from string import digits\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "063b47c0-f86c-451d-8707-b36eb57a9ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de lignes pour le train set:  7613\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nombre de lignes pour le test set:  3263\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just happened a terrible car crash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Heard about #earthquake is different cities, s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text\n",
       "0   0     NaN      NaN                 Just happened a terrible car crash\n",
       "1   2     NaN      NaN  Heard about #earthquake is different cities, s..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage de valeurs manquantes sur le train set:\n",
      "id           0.000000\n",
      "keyword      0.801261\n",
      "location    33.272035\n",
      "text         0.000000\n",
      "target       0.000000\n",
      "dtype: float64\n",
      "Pourcentage de valeurs manquantes sur le test set:\n",
      "id           0.000000\n",
      "keyword      0.796813\n",
      "location    33.864542\n",
      "text         0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"SRC_projects/nlp_disaster/train.csv\")\n",
    "test = pd.read_csv(\"SRC_projects/nlp_disaster/test.csv\")\n",
    "sample_sub = pd.read_csv(\"SRC_projects/nlp_disaster/sample_submission.csv\")\n",
    "\n",
    "print(\"nombre de lignes pour le train set: \",train.shape[0])\n",
    "display(train.head(2))\n",
    "print(\"nombre de lignes pour le test set: \",test.shape[0])\n",
    "display(test.head(2))\n",
    "\n",
    "print(\"Pourcentage de valeurs manquantes sur le train set:\")\n",
    "print(train.isna().sum()*100 / train.shape[0])\n",
    "print(\"Pourcentage de valeurs manquantes sur le test set:\")\n",
    "print(test.isna().sum()*100 / test.shape[0]) \n",
    "#On peut déja enlever la colonne location\n",
    "#Je vais faire un dropna pour enlever les valeurs manquantes, la colonne keyword pourra m'être utile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a149c77-56b7-476a-ad19-f1ee69890a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='target', ylabel='count'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=train['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fb94153-a04a-4830-87c7-6505c71756c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ede440a-743c-479b-8bf6-db7baad0cb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = str.maketrans('', '', digits)\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b3b83b-eaa7-48c6-8c0e-7744bae431cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning_encoding(df):\n",
    "    \n",
    "    df = df.drop('location', axis=1) # supprime la colonne location\n",
    "    df = df.dropna() # j'enlève les lignes possédant des valeurs nulles\n",
    "    df = df.reset_index() # je supprime l'index qui n'était pas ordonné suite au dropna\n",
    "    df = df.drop('id',axis=1) # j'enlève la colonne id\n",
    "    df = df.drop('index', axis=1) # et la colonne index\n",
    "    \n",
    "    df['text_clean'] = df['text'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True) \n",
    "    #J'enlève les URLS\n",
    "\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda x:''.join(ch for ch in x if ch.isalnum() or ch==\" \"))\n",
    "    #Je viens d'enlever toutes les caractères qui ne sont pas alphanumériques\n",
    "\n",
    "    \n",
    "\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda x: x.translate(table)).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower().strip())\n",
    "    #str.maketrans('', '', digits) nous permet d'enlever les numbers\n",
    "    #translate(str.maketrans('', '', string.punctuation)).lower() nous permet d'enlever la ponctuation et les majuscules \n",
    "\n",
    "    df['text_clean'] = df['text_clean'].apply(lambda x:\" \".join([token.lemma_ for token in nlp(x) if (token.lemma_ not in STOP_WORDS) & (token.text not in STOP_WORDS)]))\n",
    "    #tokenization et lemmatization\n",
    "\n",
    "    \n",
    "\n",
    "    tokenizer.fit_on_texts(df.text_clean)\n",
    "    df['text_encoded'] = tokenizer.texts_to_sequences(df.text_clean) #Nouvelle colonne, le texte est maintenant encodé\n",
    "\n",
    "    df['len_text_encoded'] = df['text_encoded'].apply(lambda x: len(x))\n",
    "    df = df[df['len_text_encoded']!=0] #nouvelle colonne avec la longueur de chaque liste de texte encodé\n",
    "    \n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8adc543-f653-4112-8b5c-22107efdcaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaned = cleaning_encoding(train)\n",
    "test_cleaned = cleaning_encoding(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca7f6100-de30-4e1d-aa8c-6a7314af2708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_encoded</th>\n",
       "      <th>len_text_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>We always try to bring the heavy. #metal #RT h...</td>\n",
       "      <td>0</td>\n",
       "      <td>try bring heavy metal rt</td>\n",
       "      <td>[127, 46]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#AFRICANBAZE: Breaking news:Nigeria flag set a...</td>\n",
       "      <td>1</td>\n",
       "      <td>africanbaze break newsnigeria flag set ablaze aba</td>\n",
       "      <td>[85, 128]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Crying out for more! Set me ablaze</td>\n",
       "      <td>0</td>\n",
       "      <td>cry set ablaze</td>\n",
       "      <td>[128]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>On plus side LOOK AT THE SKY LAST NIGHT IT WAS...</td>\n",
       "      <td>0</td>\n",
       "      <td>plus look sky night ablaze</td>\n",
       "      <td>[21, 176]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>@PhDSquares #mufc they've built so much hype a...</td>\n",
       "      <td>0</td>\n",
       "      <td>phdsquare mufc ve build hype new acquisition d...</td>\n",
       "      <td>[86, 6, 128]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword                                               text  target  \\\n",
       "1  ablaze  We always try to bring the heavy. #metal #RT h...       0   \n",
       "2  ablaze  #AFRICANBAZE: Breaking news:Nigeria flag set a...       1   \n",
       "3  ablaze                 Crying out for more! Set me ablaze       0   \n",
       "4  ablaze  On plus side LOOK AT THE SKY LAST NIGHT IT WAS...       0   \n",
       "5  ablaze  @PhDSquares #mufc they've built so much hype a...       0   \n",
       "\n",
       "                                          text_clean  text_encoded  \\\n",
       "1                           try bring heavy metal rt     [127, 46]   \n",
       "2  africanbaze break newsnigeria flag set ablaze aba     [85, 128]   \n",
       "3                                     cry set ablaze         [128]   \n",
       "4                         plus look sky night ablaze     [21, 176]   \n",
       "5  phdsquare mufc ve build hype new acquisition d...  [86, 6, 128]   \n",
       "\n",
       "   len_text_encoded  \n",
       "1                 2  \n",
       "2                 2  \n",
       "3                 1  \n",
       "4                 2  \n",
       "5                 3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7613 rows\n"
     ]
    }
   ],
   "source": [
    "display(train_cleaned.head())\n",
    "print(train.shape[0], \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ece417-2fc1-481a-ae9f-2784b5addc10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>text_encoded</th>\n",
       "      <th>len_text_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Birmingham Wholesale Market is ablaze BBC News...</td>\n",
       "      <td>birmingham wholesale market ablaze bbc news   ...</td>\n",
       "      <td>[8, 2, 75]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>#PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...</td>\n",
       "      <td>previouslyondoyintv toke makinwaûªs marriage c...</td>\n",
       "      <td>[128]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Check these out: http://t.co/rOI2NSmEJJ http:/...</td>\n",
       "      <td>check      nsfw</td>\n",
       "      <td>[199]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>beware world ablaze sierra leone &amp;amp; guap.</td>\n",
       "      <td>beware world ablaze sierra leone amp guap</td>\n",
       "      <td>[41, 4]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ablaze</td>\n",
       "      <td>Burning Man Ablaze! by Turban Diva http://t.co...</td>\n",
       "      <td>burn man ablaze turban diva   etsy</td>\n",
       "      <td>[9, 27]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  keyword                                               text  \\\n",
       "0  ablaze  Birmingham Wholesale Market is ablaze BBC News...   \n",
       "2  ablaze  #PreviouslyOnDoyinTv: Toke MakinwaÛªs marriag...   \n",
       "3  ablaze  Check these out: http://t.co/rOI2NSmEJJ http:/...   \n",
       "5  ablaze       beware world ablaze sierra leone &amp; guap.   \n",
       "6  ablaze  Burning Man Ablaze! by Turban Diva http://t.co...   \n",
       "\n",
       "                                          text_clean text_encoded  \\\n",
       "0  birmingham wholesale market ablaze bbc news   ...   [8, 2, 75]   \n",
       "2  previouslyondoyintv toke makinwaûªs marriage c...        [128]   \n",
       "3                                    check      nsfw        [199]   \n",
       "5          beware world ablaze sierra leone amp guap      [41, 4]   \n",
       "6                 burn man ablaze turban diva   etsy      [9, 27]   \n",
       "\n",
       "   len_text_encoded  \n",
       "0                 3  \n",
       "2                 1  \n",
       "3                 1  \n",
       "5                 2  \n",
       "6                 2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3263 rows\n"
     ]
    }
   ],
   "source": [
    "display(test_cleaned.head())\n",
    "print(test.shape[0], \"rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fe07b99-e662-445f-8a5b-e64415cfe1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pad = tf.keras.preprocessing.sequence.pad_sequences(train_cleaned.text_encoded, padding=\"post\")\n",
    "test_pad = tf.keras.preprocessing.sequence.pad_sequences(test_cleaned.text_encoded, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "525fdbfb-9015-49d8-a217-eb8bbc42ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_train_ds = tf.data.Dataset.from_tensor_slices((train_pad, train_cleaned.target.values))\n",
    "full_test_ds = tf.data.Dataset.from_tensor_slices((test_pad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d6ed583-4e5c-46b7-b062-8a8e313d9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "TAKE_SIZE = int(0.7*train_cleaned.shape[0])\n",
    "\n",
    "train_cleaned_data = full_train_ds.take(TAKE_SIZE).shuffle(TAKE_SIZE)\n",
    "train_cleaned_data = train_cleaned_data.batch(64)\n",
    "\n",
    "val_data = full_train_ds.skip(TAKE_SIZE)\n",
    "val_data = val_data.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5bd7f7d-89ff-4e92-af46-4be8d8c70ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[127  46   0]\n",
      " [ 85 128   0]\n",
      " [128   0   0]], shape=(3, 3), dtype=int32) tf.Tensor([0 1 0], shape=(3,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for tweet, target in train_cleaned_data.take(200):\n",
    "    print(tweet, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34a5bcf1-2836-4109-902a-db6ac3819a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, GRU, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "be98eb64-9429-4705-859e-a1f79c61841b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)\n",
    "model_lstm = tf.keras.Sequential([\n",
    "            Embedding(vocab_size+1, 64, input_shape=[train_pad.shape[1]], name='embedding'),\n",
    "            LSTM(units=64, return_sequences=True),\n",
    "            LSTM(units=32, return_sequences=False),\n",
    "            Dense(16, activation='relu'),\n",
    "            Dense(8, activation='relu'),\n",
    "\n",
    "            Dense(5, activation=\"softmax\", name=\"last\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c732131f-0448-4fc8-8398-06777c162a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 64)             1215872   \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, 3, 64)             33024     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " last (Dense)                (None, 5)                 45        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,262,021\n",
      "Trainable params: 1,262,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bc379ccf-700d-416b-a1dc-c55d7b0b2d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "model_lstm.compile(optimizer=optimizer,\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4569cc60-1492-49ce-8d7f-3d093cbf93e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5431 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6288 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.5372 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6307 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.5306 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6326 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.5237 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6360 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.5160 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6408 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.5074 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6466 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4983 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6509 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.4882 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6541 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.4770 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6593 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.4647 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6665 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 1.4509 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6724 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.4359 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6800 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.4194 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6857 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.4016 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.6937 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.3816 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.7041 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.3595 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.7168 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.3361 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.7264 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.3106 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.7333 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.2845 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.7435 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.2571 - sparse_categorical_accuracy: 0.3333 - val_loss: 1.7591 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.2283 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.7799 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.1998 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.8027 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.1750 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.8112 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1480 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.8202 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.1257 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.8326 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.1063 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.8486 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0897 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.8675 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0758 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.8888 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0649 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.9126 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0560 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.9370 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 1.0492 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.9620 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0439 - sparse_categorical_accuracy: 0.6667 - val_loss: 1.9872 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0399 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.0025 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0363 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.0175 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0335 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.0320 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0311 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.0459 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0290 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.0593 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 1.0271 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.0721 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0253 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.0843 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0236 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.0960 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 1.0220 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1072 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0204 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1180 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0189 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1285 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0173 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1389 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0158 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1492 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0142 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1594 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0126 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1697 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 1.0109 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1799 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0092 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1903 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 1.0076 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.2019 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 1.0058 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.2136 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 1.0041 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.2255 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0022 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.2375 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 1.0009 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.2222 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.9987 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.2097 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9969 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1999 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9952 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1939 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9933 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1918 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9913 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1935 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9891 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1990 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.9869 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.2088 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.9842 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.2223 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9816 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.2373 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9790 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.2538 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.9806 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1939 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.9745 - sparse_categorical_accuracy: 0.6667 - val_loss: 2.1440 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.9729 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.1008 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9700 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.0621 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9663 - sparse_categorical_accuracy: 1.0000 - val_loss: 2.0224 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9610 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.9812 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.9555 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.9409 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.9508 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.9019 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9442 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.8637 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9380 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.8261 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9313 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.7891 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.9236 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.7514 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9153 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.7131 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9062 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.6741 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8963 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.6346 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8859 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5944 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8742 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5535 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.8621 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.5119 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.8489 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4706 - val_sparse_categorical_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8346 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4363 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8193 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4249 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8031 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4185 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7858 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4118 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.7675 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.4046 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.7480 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3967 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.7276 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3874 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.7064 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3761 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.6846 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3624 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6619 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3474 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 33ms/step - loss: 0.6384 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3309 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.6141 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.3137 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5893 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2952 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5640 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2754 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.5384 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2546 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.5127 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2326 - val_sparse_categorical_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4869 - sparse_categorical_accuracy: 1.0000 - val_loss: 1.2091 - val_sparse_categorical_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f463c526640>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lstm.fit(train_cleaned_data,\n",
    "              epochs=100,\n",
    "              validation_data=val_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb4b7cbd-6788-4e7a-8587-1692cbf21898",
   "metadata": {},
   "source": [
    "#Opérations sur le train set:\n",
    "train = train.drop('location', axis=1) # supprime la colonne location\n",
    "train = train.dropna() # j'enlève les lignes possédant des valeurs nulles\n",
    "train = train.reset_index() # je supprime l'index qui n'était pas ordonné suite au dropna\n",
    "train = train.drop('id',axis=1) # j'enlève la colonne id\n",
    "train = train.drop('index', axis=1) # et la colonne index\n",
    "\n",
    "#Opérations sur le test set:\n",
    "test = test.drop('location', axis=1) # supprime la colonne location\n",
    "test = test.dropna() # j'enlève les lignes possédant des valeurs nulles\n",
    "test = test.reset_index() # je supprime l'index qui n'était pas ordonné suite au dropna\n",
    "test = test.drop('index', axis=1) # et la colonne index"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a8fbba0-2994-41da-b4db-571b8a216630",
   "metadata": {},
   "source": [
    "train['text_clean'] = train['text'].replace(r'http\\S+', '', regex=True).replace(r'www\\S+', '', regex=True) \n",
    "#J'enlève les URLS\n",
    "\n",
    "train['text_clean'] = train['text_clean'].apply(lambda x:''.join(ch for ch in x if ch.isalnum() or ch==\" \"))\n",
    "#Je viens d'enlever toutes les caractères qui ne sont pas alphanumériques\n",
    "#train.iloc[60:80, :]\n",
    "\n",
    "table = str.maketrans('', '', digits)\n",
    "\n",
    "train['text_clean'] = train['text_clean'].apply(lambda x: x.translate(table)).apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)).lower().strip())\n",
    "#str.maketrans('', '', digits) nous permet d'enlever les numbers\n",
    "#translate(str.maketrans('', '', string.punctuation)).lower() nous permet d'enlever la ponctuation et les majuscules \n",
    "#train.iloc[250:280, :]\n",
    "\n",
    "train['text_clean'] = train['text_clean'].apply(lambda x:\" \".join([token.lemma_ for token in nlp(x) if (token.lemma_ not in STOP_WORDS) & (token.text not in STOP_WORDS)]))\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=200)\n",
    "\n",
    "tokenizer.fit_on_texts(train.text_clean)\n",
    "train['text_encoded'] = tokenizer.texts_to_sequences(train.text_clean) #Nouvelle colonne, le texte est maintenant encodé\n",
    "\n",
    "train['len_text_encoded'] = train['text_encoded'].apply(lambda x: len(x))\n",
    "train = train[train['len_text_encoded']!=0] #nouvelle colonne avec la longueur de chaque liste de texte encodé"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
